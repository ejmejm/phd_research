defaults:
  - _self_

seed: null
wandb: false
comet_ml: false
comet_ml_workspace: phd-research
project: feature-recycling # Will appear in logging under this project
device: cpu # {cpu, cuda}

# Task parameters
task:
  name: linear_geoff # {dummy, static_linear_geoff, linear_geoff, nonlinear_geoff}
  type: regression # {classification, regression}
  n_features: 20 # Total number of input features
  n_real_features: 10 # Number of input features out of the above that are not distractors

# Input recycling parameters
# The input recycler is used if you want to insert distractor features in the input
# and the change the inputs as training progresses
# It is not used in any of the newer experiments
input_recycling:
  use_cbp_utility: false
  distractor_chance: 0.5
  recycle_rate: 0.1 # Fraction of input features that are replaced each step
  utility_decay: 0.99
  feature_protection_steps: 100
  n_start_real_features: -1

# Feature recycling parameters
# This is used to replace hidden features during training
feature_recycling:
  use_cbp_utility: false # Features will be replaced based on utility when true, otherwise replaced at random
  recycle_rate: 0.0001 # Fraction of features that are replaced each step
  utility_decay: 0.99 # Parameter used in utility computation
  feature_protection_steps: 100 # Number of steps a new feature is immune to pruning

# Train parameters
train:
  optimizer: adam # {adam, idbd}
  weight_decay: 0
  batch_size: 1
  learning_rate: 0.001 # For IDBD this is only the initial step size
  total_steps: 10000 # Number of step to train
  log_freq: 100 # Frequency of logging stats
  standardize_cumulants: false # Normalizes targets to mean of 0 and std dev of 1 when true

# Model parameters
model:
  weight_init_method: zeros # {zeros, kaiming_uniform}, only affects input layer
  n_layers: 1 # 1 layer = linear model
  hidden_dim: 256
  output_dim: 1
  activation: relu # Only used when there is more than 1 layer
  n_frozen_layers: 0 # Number of layers to freeze starting from the input layer

# IDBD parameters
idbd:
  meta_learning_rate: 0.005
  version: squared_grads # {squared_inputs, squared_grads, hvp, hessian_diagonal}, recommend not changing this
  autostep: true