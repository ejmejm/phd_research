{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847d0bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejmejm/local_projects/phd_research/phd/feature_search/scripts/full_feature_search.py:513: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path='../conf', config_name='full_feature_search')\n",
      "/tmp/ipykernel_42883/3524028346.py:6: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  hydra.initialize(config_path='../conf')\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "from phd.feature_search.scripts.full_feature_search import *\n",
    "\n",
    "if not hydra.core.global_hydra.GlobalHydra().is_initialized():\n",
    "    hydra.initialize(config_path='../conf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c555b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comet_ml: false\n",
      "comet_ml_workspace: phd-research\n",
      "device: cpu\n",
      "feature_recycling:\n",
      "  feature_protection_steps: 0\n",
      "  initial_step_size_method: constant\n",
      "  recycle_rate: 0.005\n",
      "  use_cbp_utility: true\n",
      "  use_signed_utility: false\n",
      "  utility_decay: 0.99\n",
      "input_recycling:\n",
      "  distractor_chance: 0.0\n",
      "  feature_protection_steps: 100\n",
      "  n_start_real_features: -1\n",
      "  recycle_rate: 0.0\n",
      "  use_cbp_utility: false\n",
      "  utility_decay: 0.99\n",
      "model:\n",
      "  activation: ltu\n",
      "  hidden_dim: 5120\n",
      "  n_frozen_layers: 1\n",
      "  n_layers: 2\n",
      "  output_dim: 1\n",
      "  use_bias: true\n",
      "  weight_init_method: binary\n",
      "optimizer:\n",
      "  autostep: true\n",
      "  learning_rate: 4.956427797377644e-06\n",
      "  meta_learning_rate: 0.005\n",
      "  name: idbd\n",
      "  step_size_decay: 0.0\n",
      "  version: squared_grads\n",
      "  weight_decay: 0\n",
      "project: feature-search\n",
      "representation_optimizer:\n",
      "  learning_rate: 0.001\n",
      "  name: null\n",
      "  weight_decay: 0\n",
      "seed: 20250902\n",
      "task:\n",
      "  activation: ltu\n",
      "  distractor_chance: 0.0\n",
      "  distractor_mean_range:\n",
      "  - -0.5\n",
      "  - 0.5\n",
      "  distractor_std_range:\n",
      "  - 0.1\n",
      "  - 1.0\n",
      "  flip_rate: 1.52587890625e-05\n",
      "  hidden_dim: 20\n",
      "  n_features: 20\n",
      "  n_layers: 2\n",
      "  n_real_features: 20\n",
      "  n_stationary_layers: 1\n",
      "  name: nonlinear_geoff\n",
      "  noise_std: 0.0\n",
      "  sparsity: 0.0\n",
      "  type: regression\n",
      "  weight_init: binary\n",
      "  weight_scale: 1.0\n",
      "train:\n",
      "  batch_size: 1\n",
      "  log_freq: 200\n",
      "  log_model_stats: false\n",
      "  log_optimizer_stats: false\n",
      "  log_pruning_stats: true\n",
      "  log_utility_stats: false\n",
      "  standardize_cumulants: true\n",
      "  total_steps: 1000000\n",
      "wandb: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load hydra config\n",
    "cfg = hydra.compose(\n",
    "    config_name = \"comet_sweeps/nonlinear_geoff_ablation_v5/base_config\",\n",
    "    overrides = [\n",
    "        \"wandb=true\",\n",
    "        \"comet_ml=false\",\n",
    "        \"model.hidden_dim=5120\",\n",
    "        \"optimizer.learning_rate=$\\{eval:0.003 / ${model.hidden_dim} ** 0.75\\}\",\n",
    "        \"train.log_freq=200\",\n",
    "        \"task.flip_rate=$\\{eval:2**-16\\}\",\n",
    "        \"seed=20250902\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "yaml_cfg = omegaconf.OmegaConf.to_container(cfg, resolve=True)\n",
    "print(yaml.dump(yaml_cfg, indent=2, width=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3370fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mejmejm\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ejmejm/local_projects/phd_research/phd/feature_search/notebooks/wandb/run-20250902_144721-2hz9bw3s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ejmejm/feature-search/runs/2hz9bw3s' target=\"_blank\">super-frost-127</a></strong> to <a href='https://wandb.ai/ejmejm/feature-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ejmejm/feature-search' target=\"_blank\">https://wandb.ai/ejmejm/feature-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ejmejm/feature-search/runs/2hz9bw3s' target=\"_blank\">https://wandb.ai/ejmejm/feature-search/runs/2hz9bw3s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Run the feature recycling experiment.\"\"\"\n",
    "assert cfg.model.n_layers == 2, \"Only 2-layer models are supported!\"\n",
    "\n",
    "cfg = init_experiment(cfg.project, cfg)\n",
    "\n",
    "task, task_iterator, model, criterion, optimizer, repr_optimizer, recycler, cbp_tracker = \\\n",
    "    prepare_ltu_geoff_experiment(cfg)\n",
    "model.forward = model_distractor_forward_pass.__get__(model)\n",
    "\n",
    "distractor_tracker = DistractorTracker(\n",
    "    model,\n",
    "    cfg.task.distractor_chance,\n",
    "    tuple(cfg.task.distractor_mean_range),\n",
    "    tuple(cfg.task.distractor_std_range),\n",
    "    seed = seed_from_string(cfg.seed, 'distractor_tracker'),\n",
    ")\n",
    "\n",
    "# run_experiment(\n",
    "#     cfg, task, task_iterator, model, criterion, optimizer,\n",
    "#     repr_optimizer, cbp_tracker, distractor_tracker,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32585138",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RingBuffer:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.buffer = [None] * size\n",
    "        self.index = 0\n",
    "\n",
    "    def append(self, item):\n",
    "        self.buffer[self.index] = item\n",
    "        self.index = (self.index + 1) % self.size\n",
    "\n",
    "    def get_buffer(self):\n",
    "        return self.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "105d76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model, criterion, optimizer, repr_optimizer, use_bias,\n",
    "    cumulant_stats, distractor_tracker, inputs, targets,\n",
    "    effective_lr_accum,\n",
    "):\n",
    "    # Forward pass\n",
    "    outputs, param_inputs = model(\n",
    "        inputs, distractor_tracker.replace_features, use_bias)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if cfg.train.standardize_cumulants:\n",
    "            baseline_pred = torch.zeros_like(targets)\n",
    "        else:\n",
    "            baseline_pred = cumulant_stats.running_mean.cpu().view(1, 1)\n",
    "        mean_pred_loss = criterion(baseline_pred, targets)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    if repr_optimizer is not None:\n",
    "        repr_optimizer.zero_grad()\n",
    "    \n",
    "    if isinstance(optimizer, IDBD):\n",
    "        # Mean over batch dimension\n",
    "        param_inputs = {k: v.mean(dim=0) for k, v in param_inputs.items()}\n",
    "        retain_graph = optimizer.version == 'squared_grads'\n",
    "        loss.backward(retain_graph=retain_graph)\n",
    "        stats = optimizer.step(outputs, param_inputs)\n",
    "        effective_lr_accum += list(stats.values())[0]['effective_step_size'].mean().item()\n",
    "    else:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if repr_optimizer is not None:\n",
    "        repr_optimizer.step()\n",
    "        \n",
    "    return loss.item(), mean_pred_loss.item(), effective_lr_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5380d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_bias = cfg.model.get('use_bias', True)\n",
    "    \n",
    "# Distractor setup\n",
    "n_hidden_units = model.layers[-1].in_features\n",
    "first_feature_idx = 1 if use_bias else 0 # First feature is bias if enabled\n",
    "distractor_tracker.process_new_features(list(range(first_feature_idx, n_hidden_units)))\n",
    "\n",
    "# Training loop\n",
    "step = 0\n",
    "prev_pruned_idxs = set()\n",
    "prune_layer = model.layers[-2]\n",
    "# pbar = tqdm(total=cfg.train.total_steps, desc='Training')\n",
    "\n",
    "# Flags\n",
    "log_utility_stats = cfg.train.get('log_utility_stats', False)\n",
    "log_pruning_stats = cfg.train.get('log_pruning_stats', False)\n",
    "log_model_stats = cfg.train.get('log_model_stats', False)\n",
    "log_optimizer_stats = cfg.train.get('log_optimizer_stats', False)\n",
    "\n",
    "# Initialize accumulators\n",
    "cumulant_stats = StandardizationStats(gamma=0.99)\n",
    "cumulative_loss = np.float128(0.0)\n",
    "loss_accum = 0.0\n",
    "mean_pred_loss_accum = 0.0\n",
    "effective_lr_accum = 0.0\n",
    "pruned_accum = 0\n",
    "pruned_newest_feature_accum = 0\n",
    "n_steps_since_log = 0\n",
    "total_pruned = 0\n",
    "prune_thresholds = []\n",
    "target_buffer = []\n",
    "\n",
    "# Replay stuff\n",
    "replay_buffer = RingBuffer(size=200)\n",
    "n_replay_steps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d4029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 | loss: 1.0259\n",
      "step: 200 | loss: 1.5484\n",
      "step: 400 | loss: 0.6562\n",
      "step: 600 | loss: 0.4068\n",
      "step: 800 | loss: 0.3392\n",
      "step: 1000 | loss: 0.3478\n",
      "step: 1200 | loss: 0.2463\n",
      "step: 1400 | loss: 0.2874\n",
      "step: 1600 | loss: 0.2391\n",
      "step: 1800 | loss: 0.2756\n",
      "step: 2000 | loss: 0.2947\n",
      "step: 2200 | loss: 0.2330\n",
      "step: 2400 | loss: 0.2811\n",
      "step: 2600 | loss: 0.2751\n",
      "step: 2800 | loss: 0.2734\n",
      "step: 3000 | loss: 0.2747\n",
      "step: 3200 | loss: 0.2614\n",
      "step: 3400 | loss: 0.2595\n",
      "step: 3600 | loss: 0.2614\n",
      "step: 3800 | loss: 0.2627\n",
      "step: 4000 | loss: 0.2092\n",
      "step: 4200 | loss: 0.2367\n",
      "step: 4400 | loss: 0.2447\n",
      "step: 4600 | loss: 0.2243\n",
      "step: 4800 | loss: 0.2467\n",
      "step: 5000 | loss: 0.3058\n",
      "step: 5200 | loss: 0.2467\n",
      "step: 5400 | loss: 0.1995\n",
      "step: 5600 | loss: 0.2322\n",
      "step: 5800 | loss: 0.2233\n",
      "step: 6000 | loss: 0.2597\n",
      "step: 6200 | loss: 0.1708\n",
      "step: 6400 | loss: 0.3015\n",
      "step: 6600 | loss: 0.2502\n",
      "step: 6800 | loss: 0.2854\n",
      "step: 7000 | loss: 0.2322\n",
      "step: 7200 | loss: 0.2765\n",
      "step: 7400 | loss: 0.2615\n",
      "step: 7600 | loss: 0.3110\n",
      "step: 7800 | loss: 0.2753\n",
      "step: 8000 | loss: 0.2540\n",
      "step: 8200 | loss: 0.2372\n",
      "step: 8400 | loss: 0.2539\n",
      "step: 8600 | loss: 0.2269\n",
      "step: 8800 | loss: 0.2234\n",
      "step: 9000 | loss: 0.2385\n",
      "step: 9200 | loss: 0.1940\n",
      "step: 9400 | loss: 0.2246\n",
      "step: 9600 | loss: 0.2869\n",
      "step: 9800 | loss: 0.3137\n",
      "step: 10000 | loss: 0.2913\n",
      "step: 10200 | loss: 0.2917\n",
      "step: 10400 | loss: 0.2624\n",
      "step: 10600 | loss: 0.2802\n",
      "step: 10800 | loss: 0.2854\n",
      "step: 11000 | loss: 0.2808\n",
      "step: 11200 | loss: 0.2568\n",
      "step: 11400 | loss: 0.2323\n",
      "step: 11600 | loss: 0.2249\n",
      "step: 11800 | loss: 0.2670\n",
      "step: 12000 | loss: 0.2730\n",
      "step: 12200 | loss: 0.1860\n",
      "step: 12400 | loss: 0.2479\n",
      "step: 12600 | loss: 0.2020\n",
      "step: 12800 | loss: 0.2697\n",
      "step: 13000 | loss: 0.2570\n",
      "step: 13200 | loss: 0.2883\n",
      "step: 13400 | loss: 0.2544\n",
      "step: 13600 | loss: 0.2740\n",
      "step: 13800 | loss: 0.2460\n",
      "step: 14000 | loss: 0.2702\n",
      "step: 14200 | loss: 0.2723\n",
      "step: 14400 | loss: 0.2219\n",
      "step: 14600 | loss: 0.2424\n",
      "step: 14800 | loss: 0.2228\n",
      "step: 15000 | loss: 0.2390\n",
      "step: 15200 | loss: 0.2476\n",
      "step: 15400 | loss: 0.2289\n",
      "step: 15600 | loss: 0.1948\n",
      "step: 15800 | loss: 0.2265\n",
      "step: 16000 | loss: 0.2310\n",
      "step: 16200 | loss: 0.2142\n",
      "step: 16400 | loss: 0.2086\n",
      "step: 16600 | loss: 0.3114\n",
      "step: 16800 | loss: 0.2436\n",
      "step: 17000 | loss: 0.2720\n",
      "step: 17200 | loss: 0.2952\n",
      "step: 17400 | loss: 0.2992\n",
      "step: 17600 | loss: 0.2846\n",
      "step: 17800 | loss: 0.2386\n",
      "step: 18000 | loss: 0.2345\n",
      "step: 18200 | loss: 0.2499\n",
      "step: 18400 | loss: 0.2632\n",
      "step: 18600 | loss: 0.2651\n",
      "step: 18800 | loss: 0.2774\n",
      "step: 19000 | loss: 0.3110\n",
      "step: 19200 | loss: 0.3305\n",
      "step: 19400 | loss: 0.2589\n",
      "step: 19600 | loss: 0.2192\n",
      "step: 19800 | loss: 0.2906\n",
      "step: 20000 | loss: 0.2903\n",
      "step: 20200 | loss: 0.2547\n",
      "step: 20400 | loss: 0.3089\n",
      "step: 20600 | loss: 0.2759\n",
      "step: 20800 | loss: 0.2467\n",
      "step: 21000 | loss: 0.2796\n",
      "step: 21200 | loss: 0.2666\n",
      "step: 21400 | loss: 0.2661\n",
      "step: 21600 | loss: 0.2570\n",
      "step: 21800 | loss: 0.2859\n",
      "step: 22000 | loss: 0.2526\n",
      "step: 22200 | loss: 0.2685\n",
      "step: 22400 | loss: 0.2830\n",
      "step: 22600 | loss: 0.2435\n",
      "step: 22800 | loss: 0.2960\n",
      "step: 23000 | loss: 0.3864\n",
      "step: 23200 | loss: 0.4100\n",
      "step: 23400 | loss: 0.3973\n",
      "step: 23600 | loss: 0.3484\n",
      "step: 23800 | loss: 0.3147\n",
      "step: 24000 | loss: 0.2948\n",
      "step: 24200 | loss: 0.3498\n",
      "step: 24400 | loss: 0.3105\n",
      "step: 24600 | loss: 0.2731\n",
      "step: 24800 | loss: 0.2870\n",
      "step: 25000 | loss: 0.3221\n",
      "step: 25200 | loss: 0.3093\n",
      "step: 25400 | loss: 0.3222\n"
     ]
    }
   ],
   "source": [
    "while step < cfg.train.total_steps:\n",
    "\n",
    "    # Generate batch of data\n",
    "    inputs, targets = next(task_iterator)\n",
    "\n",
    "    # Add noise to targets\n",
    "    if cfg.task.noise_std > 0:\n",
    "        targets += torch.randn_like(targets) * cfg.task.noise_std\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        standardized_targets, cumulant_stats = standardize_targets(targets, cumulant_stats)\n",
    "    \n",
    "    if cfg.train.standardize_cumulants:\n",
    "        targets = standardized_targets\n",
    "    target_buffer.extend(targets.view(-1).tolist())\n",
    "    \n",
    "    features, targets = inputs.to(cfg.device), targets.to(cfg.device)\n",
    "\n",
    "    # Reset weights and optimizer states for recycled features\n",
    "    if cbp_tracker is not None:\n",
    "        if log_pruning_stats:\n",
    "            pre_prune_utilities = cbp_tracker.get_statistics(prune_layer)['utility']\n",
    "\n",
    "        if isinstance(cbp_tracker, SignedCBPTracker):\n",
    "            pruned_idxs = cbp_tracker.prune_features(targets)\n",
    "        else:\n",
    "            pruned_idxs = cbp_tracker.prune_features()\n",
    "        n_pruned = sum([len(idxs) for idxs in pruned_idxs.values()])\n",
    "        total_pruned += n_pruned\n",
    "\n",
    "        if prune_layer in pruned_idxs and len(pruned_idxs[prune_layer]) > 0:\n",
    "            new_feature_idxs = pruned_idxs[prune_layer].tolist()\n",
    "            distractor_process_idxs = new_feature_idxs\n",
    "\n",
    "            # Don't turn bias into a distractor\n",
    "            if use_bias:\n",
    "                distractor_process_idxs = [idx for idx in distractor_process_idxs if idx != 0]\n",
    "\n",
    "            # Turn some features into distractors\n",
    "            distractor_tracker.process_new_features(distractor_process_idxs)\n",
    "\n",
    "            # Log pruning statistics\n",
    "            pruned_accum += len(new_feature_idxs)\n",
    "            n_new_pruned_features = len(set(new_feature_idxs).intersection(prev_pruned_idxs))\n",
    "            pruned_newest_feature_accum += n_new_pruned_features\n",
    "            prev_pruned_idxs = set(new_feature_idxs)\n",
    "            \n",
    "            if log_pruning_stats:\n",
    "                prune_thresholds.append(pre_prune_utilities[new_feature_idxs].max().item())\n",
    "    \n",
    "    # Train step\n",
    "    for _ in range(n_replay_steps):\n",
    "        loss, mean_pred_loss, effective_lr_accum = train_step(\n",
    "            model, criterion, optimizer, repr_optimizer, use_bias, cumulant_stats,\n",
    "            distractor_tracker, inputs, targets, effective_lr_accum)\n",
    "    \n",
    "    # # Forward pass\n",
    "    # outputs, param_inputs = model(\n",
    "    #     features, distractor_tracker.replace_features, use_bias)\n",
    "    # loss = criterion(outputs, targets)\n",
    "    \n",
    "    # with torch.no_grad():\n",
    "    #     if cfg.train.standardize_cumulants:\n",
    "    #         baseline_pred = torch.zeros_like(targets)\n",
    "    #     else:\n",
    "    #         baseline_pred = cumulant_stats.running_mean.cpu().view(1, 1)\n",
    "    #     mean_pred_loss = criterion(baseline_pred, targets)\n",
    "\n",
    "    # # Backward pass\n",
    "    # optimizer.zero_grad()\n",
    "    # if repr_optimizer is not None:\n",
    "    #     repr_optimizer.zero_grad()\n",
    "    \n",
    "    # if isinstance(optimizer, IDBD):\n",
    "    #     # Mean over batch dimension\n",
    "    #     param_inputs = {k: v.mean(dim=0) for k, v in param_inputs.items()}\n",
    "    #     retain_graph = optimizer.version == 'squared_grads'\n",
    "    #     loss.backward(retain_graph=retain_graph)\n",
    "    #     stats = optimizer.step(outputs, param_inputs)\n",
    "    #     effective_lr_accum += list(stats.values())[0]['effective_step_size'].mean().item()\n",
    "    # else:\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step()\n",
    "        \n",
    "    # if repr_optimizer is not None:\n",
    "    #     repr_optimizer.step()\n",
    "    \n",
    "    # Accumulate metrics\n",
    "    loss_accum += loss\n",
    "    cumulative_loss += loss\n",
    "    mean_pred_loss_accum += mean_pred_loss\n",
    "    n_steps_since_log += 1\n",
    "    \n",
    "    # Log metrics\n",
    "    if step % cfg.train.log_freq == 0:\n",
    "        n_distractors = distractor_tracker.distractor_mask.sum().item()\n",
    "        n_real_features = distractor_tracker.distractor_mask.numel() - n_distractors\n",
    "        metrics = {\n",
    "            'step': step,\n",
    "            'samples': step * cfg.train.batch_size,\n",
    "            'loss': loss_accum / n_steps_since_log,\n",
    "            'cumulative_loss': float(cumulative_loss),\n",
    "            'mean_prediction_loss': mean_pred_loss_accum / n_steps_since_log,\n",
    "            'squared_targets': torch.tensor(target_buffer).square().mean().item(),\n",
    "            'n_distractors': n_distractors,\n",
    "            'n_real_features': n_real_features,\n",
    "        }\n",
    "\n",
    "        if log_pruning_stats:\n",
    "            if pruned_accum > 0:\n",
    "                metrics['fraction_pruned_were_new'] = pruned_newest_feature_accum / pruned_accum\n",
    "                pruned_newest_feature_accum = 0\n",
    "                pruned_accum = 0\n",
    "            metrics['units_pruned'] = total_pruned\n",
    "            if len(prune_thresholds) > 0:\n",
    "                metrics['prune_threshold'] = np.mean(prune_thresholds)\n",
    "            prune_thresholds.clear()\n",
    "        \n",
    "        if log_utility_stats:\n",
    "            all_utilities = cbp_tracker.get_statistics(prune_layer)['utility']\n",
    "            distractor_mask = distractor_tracker.distractor_mask\n",
    "            real_utilities = all_utilities[~distractor_mask]\n",
    "            distractor_utilities = all_utilities[distractor_mask]\n",
    "            \n",
    "            cumulative_utility = all_utilities.sum().item()\n",
    "            metrics['cumulative_utility'] = cumulative_utility\n",
    "            \n",
    "            if len(real_utilities) > 0:\n",
    "                metrics['real_utility_median'] = real_utilities.median().item()\n",
    "                metrics['real_utility_25th'] = real_utilities.quantile(0.25).item()\n",
    "                metrics['real_utility_75th'] = real_utilities.quantile(0.75).item()\n",
    "            \n",
    "            if len(distractor_utilities) > 0:\n",
    "                metrics['distractor_utility_median'] = distractor_utilities.median().item()\n",
    "                metrics['distractor_utility_25th'] = distractor_utilities.quantile(0.25).item() \n",
    "                metrics['distractor_utility_75th'] = distractor_utilities.quantile(0.75).item()\n",
    "        \n",
    "        if log_optimizer_stats and isinstance(optimizer, IDBD):\n",
    "            states = list(optimizer.state.values())\n",
    "            assert len(states) == 1, \"There should not be more than one optimizer state!\"\n",
    "            state = states[0]\n",
    "            step_sizes = torch.exp(state['beta'])\n",
    "            metrics['mean_step_size'] = step_sizes.mean().item()\n",
    "            metrics['median_step_size'] = step_sizes.median().item()\n",
    "            metrics['effective_lr'] = effective_lr_accum / n_steps_since_log\n",
    "        effective_lr_accum = 0.0\n",
    "\n",
    "        log_metrics(metrics, cfg, step=step)\n",
    "        \n",
    "        print(f'step: {step} | loss: {metrics[\"loss\"]:.4f}')\n",
    "        # pbar.set_postfix(loss=metrics['loss'])\n",
    "        # pbar.update(cfg.train.log_freq)\n",
    "        \n",
    "        # Reset accumulators\n",
    "        loss_accum = 0.0\n",
    "        mean_pred_loss_accum = 0.0\n",
    "        n_steps_since_log = 0\n",
    "        target_buffer = []\n",
    "\n",
    "    step += 1\n",
    "\n",
    "# pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13346ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_experiment(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedcb75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bdc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ecaee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5479af0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9806c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c60acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
