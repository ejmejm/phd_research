{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f8d329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "import hydra\n",
    "\n",
    "from phd.feature_search.scripts.ensemble_feature_search import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2cda782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hydra.core.global_hydra.GlobalHydra().is_initialized():\n",
    "    hydra.initialize(config_path=\"../../conf\")\n",
    "\n",
    "# Load hydra config\n",
    "cfg = hydra.compose(\n",
    "    config_name = \"comet_sweeps/nonlinear_geoff_ablation_v5/base_config.yaml\",\n",
    "    overrides = [\n",
    "        \"task.n_features=30\",\n",
    "        \"task.n_real_features=30\",\n",
    "        \"task.noise_std=0.0\",\n",
    "        \"train.total_steps=2_000_000\",\n",
    "        \"seed=20250812\",\n",
    "        \"train.log_freq=500\",\n",
    "        \"comet_ml=false\",\n",
    "        \"wandb=false\",\n",
    "        \"model.hidden_dim=1280\", #1280\",\n",
    "        \"+model.ensemble_feature_selection_method=random\",\n",
    "        \"+model.feature_utility_mode=mean\",\n",
    "        \"+model.ensemble_utility_mode=objective_improvement\",\n",
    "        \"+model.prediction_mode=mean\",\n",
    "        \"+feature_recycling.ensemble_recycle_rate=0.0\",\n",
    "        \"+model.ensemble_dim=1280\",\n",
    "        \"+model.n_ensemble_members=1\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# yaml_cfg = omegaconf.OmegaConf.to_container(cfg, resolve=True)\n",
    "# print(yaml.dump(yaml_cfg, indent=2, width=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a074e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every time a new feature is introduced, check if it should be kept or not\n",
    "# If it should be kept, track how long for the feature to rise in utility to top 10%\n",
    "# But what is utility in an ensemble? I think for now I can just say it's the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "207cfb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 16000/2000000 [06:04<12:33:47, 43.87it/s, loss=0.9]\n"
     ]
    }
   ],
   "source": [
    "cfg = init_experiment(cfg.project, cfg)\n",
    "\n",
    "task, task_iterator, model, criterion, optimizer, repr_optimizer, recycler = \\\n",
    "    prepare_ltu_geoff_experiment(cfg)\n",
    "model.forward = model_distractor_forward_pass.__get__(model)\n",
    "\n",
    "distractor_tracker = DistractorTracker(\n",
    "    model,\n",
    "    cfg.task.distractor_chance,\n",
    "    tuple(cfg.task.distractor_mean_range),\n",
    "    tuple(cfg.task.distractor_std_range),\n",
    "    seed = seed_from_string(cfg.seed, 'distractor_tracker'),\n",
    ")\n",
    "\n",
    "# Gives a 1:1 hidden dim to ensemble input mapping\n",
    "model.ensemble_input_ids = torch.arange(\n",
    "        0, model.n_ensemble_members * model.ensemble_dim,\n",
    "        dtype = torch.long,\n",
    "        device = model.ensemble_input_ids.device,\n",
    "    ).reshape(model.n_ensemble_members, model.ensemble_dim)\n",
    "\n",
    "# Distractor setup\n",
    "n_hidden_units = model.input_layer.out_features\n",
    "distractor_tracker.process_new_features(torch.arange(n_hidden_units))\n",
    "\n",
    "# Training loop\n",
    "step = 0\n",
    "prev_pruned_idxs = set()\n",
    "prune_layer = model.activation\n",
    "pbar = tqdm(total=cfg.train.total_steps, desc='Training')\n",
    "\n",
    "# Flags\n",
    "log_utility_stats = cfg.train.get('log_utility_stats', False)\n",
    "log_pruning_stats = cfg.train.get('log_pruning_stats', False)\n",
    "log_model_stats = cfg.train.get('log_model_stats', False)\n",
    "\n",
    "# Initialize accumulators\n",
    "cumulant_stats = StandardizationStats(gamma=0.99)\n",
    "pruning_state = PruningState()\n",
    "cumulative_loss = np.float128(0.0)\n",
    "loss_accum = 0.0\n",
    "ensemble_loss_accum = 0.0\n",
    "mean_pred_loss_accum = 0.0\n",
    "pruned_accum = 0\n",
    "pruned_newest_feature_accum = 0\n",
    "n_steps_since_log = 0\n",
    "total_features_pruned = 0\n",
    "total_ensembles_pruned = 0\n",
    "prune_thresholds = []\n",
    "target_buffer = []\n",
    "\n",
    "times_to_top_10_percent = [] # Tuples of feature creation step and time to top 10%\n",
    "tracked_features = {} # Maps feature idx to the step it was introduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "33fa42cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature match counts: [24, 24, 25, 24, 26, 26, 25, 25, 24, 23, 25, 26, 24, 24, 24, 24, 28, 24, 26, 24]\n"
     ]
    }
   ],
   "source": [
    "# Get, for each target feature, how closely the closest learning network hidden unit matches it\n",
    "optimal_feature_weights = task.weights[0].T\n",
    "\n",
    "def compute_best_feature_match_counts(model, task):\n",
    "    optimal_feature_weights = task.weights[0].T\n",
    "    feature_matches = model.input_layer.weight.unsqueeze(dim=1) == optimal_feature_weights.unsqueeze(dim=0)\n",
    "    positive_feature_match_counts = feature_matches.sum(dim=2)\n",
    "    negative_feature_match_counts = (~feature_matches).sum(dim=2)\n",
    "    feature_match_counts = torch.maximum(positive_feature_match_counts, negative_feature_match_counts)\n",
    "    best_feature_match_counts = feature_match_counts.max(dim=0).values\n",
    "    return best_feature_match_counts\n",
    "\n",
    "best_feature_match_counts = compute_best_feature_match_counts(model, task)  \n",
    "\n",
    "print(f'Best feature match counts: {best_feature_match_counts.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5455902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 98\u001b[0m\n\u001b[1;32m     95\u001b[0m ensemble_loss_sum \u001b[38;5;241m=\u001b[39m aux[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble_losses\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241m.\u001b[39mstandardize_cumulants:\n\u001b[1;32m     99\u001b[0m         baseline_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(targets)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.10/site-packages/omegaconf/dictconfig.py:351\u001b[0m, in \u001b[0;36mDictConfig.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m()\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_DEFAULT_MARKER_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConfigKeyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_and_raise(\n\u001b[1;32m    356\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cause\u001b[38;5;241m=\u001b[39me, type_override\u001b[38;5;241m=\u001b[39mConfigAttributeError\n\u001b[1;32m    357\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.10/site-packages/omegaconf/dictconfig.py:451\u001b[0m, in \u001b[0;36mDictConfig._get_impl\u001b[0;34m(self, key, default_value, validate_key)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Node)\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_with_default\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_value\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.10/site-packages/omegaconf/basecontainer.py:105\u001b[0m, in \u001b[0;36mBaseContainer._resolve_with_default\u001b[0;34m(self, key, value, default_value)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingMandatoryValue(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing mandatory value: $FULL_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m resolved_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_resolve_interpolation(\n\u001b[1;32m     99\u001b[0m     parent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    100\u001b[0m     key\u001b[38;5;241m=\u001b[39mkey,\n\u001b[1;32m    101\u001b[0m     value\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[1;32m    102\u001b[0m     throw_on_resolution_failure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    103\u001b[0m )\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_node\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.10/site-packages/omegaconf/_utils.py:748\u001b[0m, in \u001b[0;36m_get_value\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_value\u001b[39m(value: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Container, UnionNode\n\u001b[0;32m--> 748\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnodes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ValueNode\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ValueNode):\n\u001b[1;32m    751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39m_value()\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:404\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while step < cfg.train.total_steps:\n",
    "\n",
    "    ### Data Processing ###\n",
    "\n",
    "    # Generate batch of data\n",
    "    inputs, targets = next(task_iterator)\n",
    "\n",
    "    # Add noise to targets\n",
    "    if cfg.task.noise_std > 0:\n",
    "        targets += torch.randn_like(targets) * cfg.task.noise_std\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        standardized_targets, cumulant_stats = standardize_targets(targets, cumulant_stats)\n",
    "    \n",
    "    if cfg.train.standardize_cumulants:\n",
    "        targets = standardized_targets\n",
    "    target_buffer.extend(targets.view(-1).tolist())\n",
    "    \n",
    "    features, targets = inputs.to(cfg.device), targets.to(cfg.device)\n",
    "\n",
    "\n",
    "    ### Pruning ###\n",
    "\n",
    "    if log_pruning_stats:\n",
    "        pre_prune_feature_utilities = model.feature_utilities.ravel().cpu().clone().numpy()\n",
    "        pre_prune_ensemble_utilities = model.ensemble_utilities.cpu().clone().numpy()\n",
    "    \n",
    "    # Prune the model if necessary\n",
    "    prune_results = prune_model(\n",
    "        model, optimizer, distractor_tracker, pruning_state, cfg)\n",
    "    \n",
    "    # Update pruning metrics\n",
    "    total_features_pruned += prune_results['n_features_pruned']\n",
    "    total_ensembles_pruned += prune_results['n_ensembles_pruned']\n",
    "    \n",
    "    if prune_results['n_features_pruned'] > 0:\n",
    "        feature_idxs_pruned = prune_results['feature_idxs_pruned'].tolist()\n",
    "        \n",
    "        # Log pruning statistics\n",
    "        pruned_accum += len(feature_idxs_pruned)\n",
    "        n_new_pruned_features = len(set(feature_idxs_pruned).intersection(prev_pruned_idxs))\n",
    "        pruned_newest_feature_accum += n_new_pruned_features\n",
    "        prev_pruned_idxs = set(feature_idxs_pruned)\n",
    "        \n",
    "        if log_pruning_stats:\n",
    "            prune_thresholds.append(pre_prune_feature_utilities[feature_idxs_pruned].max())\n",
    "            \n",
    "        # Track new features\n",
    "        for feature_idx in feature_idxs_pruned:\n",
    "            # If the feature is pruned while still being tracked, then it never made it to top 10%\n",
    "            if feature_idx in tracked_features:\n",
    "                times_to_top_10_percent.append(\n",
    "                    (tracked_features[feature_idx], -1))\n",
    "                tracked_features.pop(feature_idx)\n",
    "            \n",
    "        new_feature_weights = model.input_layer.weight[feature_idxs_pruned]\n",
    "        feature_matches = new_feature_weights.unsqueeze(dim=1) == optimal_feature_weights.unsqueeze(dim=0)\n",
    "        positive_match_counts = feature_matches.sum(dim=2)\n",
    "        negative_match_counts = (~feature_matches).sum(dim=2)\n",
    "        match_counts = torch.maximum(positive_match_counts, negative_match_counts) # (n_features_pruned, n_target_features)\n",
    "        feature_improvement_matrix = match_counts > best_feature_match_counts.unsqueeze(dim=0)\n",
    "        \n",
    "        # Bool for each new feature that indicates if it is an overall improvement\n",
    "        new_best_feature = feature_improvement_matrix.any(dim=1) # (n_features_pruned,)\n",
    "        \n",
    "        best_feature_match_counts = torch.maximum(\n",
    "            best_feature_match_counts,\n",
    "            match_counts.max(dim=0).values,\n",
    "        )\n",
    "        \n",
    "        for i in range(len(feature_idxs_pruned)):\n",
    "            feature_idx = feature_idxs_pruned[i]\n",
    "            if new_best_feature[i]:\n",
    "                tracked_features[feature_idx] = step\n",
    "    \n",
    "    \n",
    "    ### Track time to top 10% ###\n",
    "    \n",
    "    utility_treshold = torch.quantile(model.feature_utilities, 0.9)\n",
    "    feature_utilities = model.feature_utilities.cpu().clone().numpy()\n",
    "    for feature_idx in list(tracked_features.keys()):\n",
    "        if feature_utilities[feature_idx] > utility_treshold:\n",
    "            times_to_top_10_percent.append(\n",
    "                (tracked_features[feature_idx], step - tracked_features[feature_idx]))\n",
    "            tracked_features.pop(feature_idx)\n",
    "    \n",
    "    \n",
    "    ### Forward Pass ###\n",
    "    \n",
    "    outputs, param_inputs, aux = model(\n",
    "        features, targets, update_state=True,\n",
    "        distractor_callback=distractor_tracker.replace_features,\n",
    "    )\n",
    "    loss = aux['loss']\n",
    "    ensemble_loss_sum = aux['ensemble_losses'].sum()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if cfg.train.standardize_cumulants:\n",
    "            baseline_pred = torch.zeros_like(targets)\n",
    "        else:\n",
    "            baseline_pred = cumulant_stats.running_mean.cpu().view(1, 1)\n",
    "        mean_pred_loss = criterion(baseline_pred, targets)\n",
    "\n",
    "\n",
    "    ### Backward Pass ###\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    if repr_optimizer is not None:\n",
    "        repr_optimizer.zero_grad()\n",
    "    \n",
    "    if isinstance(optimizer, IDBD):\n",
    "        # Mean over batch dimension\n",
    "        param_inputs = {k: v.mean(dim=0) for k, v in param_inputs.items()}\n",
    "        retain_graph = optimizer.version == 'squared_grads'\n",
    "        ensemble_loss_sum.backward(retain_graph=retain_graph)\n",
    "        optimizer.step(aux['ensemble_predictions'], param_inputs)\n",
    "    else:\n",
    "        ensemble_loss_sum.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if repr_optimizer is not None:\n",
    "        repr_optimizer.step()\n",
    "        \n",
    "    \n",
    "    ### Metrics ###\n",
    "    \n",
    "    # Accumulate metrics\n",
    "    loss_accum += loss.item()\n",
    "    ensemble_loss_accum += ensemble_loss_sum.item()\n",
    "    cumulative_loss += loss.item()\n",
    "    mean_pred_loss_accum += mean_pred_loss.item()\n",
    "    n_steps_since_log += 1\n",
    "    \n",
    "    \n",
    "    ### Logging ###\n",
    "    \n",
    "    if step % cfg.train.log_freq == 0:\n",
    "        n_distractors = distractor_tracker.distractor_mask.sum().item()\n",
    "        n_real_features = distractor_tracker.distractor_mask.numel() - n_distractors\n",
    "        metrics = {\n",
    "            'step': step,\n",
    "            'samples': step * cfg.train.batch_size,\n",
    "            'loss': loss_accum / n_steps_since_log,\n",
    "            'avg_ensemble_loss': ensemble_loss_accum / model.n_ensemble_members / n_steps_since_log,\n",
    "            'cumulative_loss': float(cumulative_loss),\n",
    "            'mean_prediction_loss': mean_pred_loss_accum / n_steps_since_log,\n",
    "            'squared_targets': torch.tensor(target_buffer).square().mean().item(),\n",
    "            'n_distractors': n_distractors,\n",
    "            'n_real_features': n_real_features,\n",
    "        }\n",
    "\n",
    "        # Add model statistics separately for real and distractor features\n",
    "        if log_model_stats:\n",
    "            real_feature_masks = [\n",
    "                torch.ones(model.layers[0].weight.shape[1], dtype=torch.bool, device=model.layers[0].weight.device),\n",
    "                ~distractor_tracker.distractor_mask,\n",
    "            ]\n",
    "            metrics.update(get_model_statistics(\n",
    "                model, features, param_inputs, real_feature_masks, metric_prefix='real_'))\n",
    "            \n",
    "            distractor_feature_masks = [\n",
    "                real_feature_masks[0],\n",
    "                distractor_tracker.distractor_mask,\n",
    "            ]\n",
    "            metrics.update(get_model_statistics(\n",
    "                model, features, param_inputs, distractor_feature_masks, metric_prefix='distractor_'))\n",
    "\n",
    "        log_metrics(metrics, cfg, step=step)\n",
    "        \n",
    "        pbar.set_postfix(loss=metrics['loss'])\n",
    "        pbar.update(cfg.train.log_freq)\n",
    "        \n",
    "        # Reset accumulators\n",
    "        loss_accum = 0.0\n",
    "        mean_pred_loss_accum = 0.0\n",
    "        ensemble_loss_accum = 0.0\n",
    "        n_steps_since_log = 0\n",
    "        target_buffer = []\n",
    "\n",
    "    step += 1\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "25a21a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(40, -1),\n",
       " (40, -1),\n",
       " (57, -1),\n",
       " (145, -1),\n",
       " (208, -1),\n",
       " (230, -1),\n",
       " (249, -1),\n",
       " (333, -1),\n",
       " (12, -1),\n",
       " (411, -1),\n",
       " (503, -1),\n",
       " (542, -1),\n",
       " (753, -1),\n",
       " (754, -1),\n",
       " (776, -1),\n",
       " (843, -1),\n",
       " (137, -1),\n",
       " (913, -1),\n",
       " (992, -1),\n",
       " (1425, -1),\n",
       " (1597, -1),\n",
       " (1745, -1),\n",
       " (180, -1),\n",
       " (97, 1972),\n",
       " (37, -1),\n",
       " (2432, -1),\n",
       " (2593, -1),\n",
       " (2673, -1),\n",
       " (3114, -1),\n",
       " (3733, -1),\n",
       " (4028, -1),\n",
       " (4103, -1),\n",
       " (5303, -1),\n",
       " (5689, -1),\n",
       " (6935, -1),\n",
       " (7116, -1),\n",
       " (8332, -1),\n",
       " (9283, -1),\n",
       " (10542, -1),\n",
       " (11431, -1),\n",
       " (14061, -1),\n",
       " (4487, 10253),\n",
       " (15549, -1),\n",
       " (17376, -1),\n",
       " (17564, -1),\n",
       " (20383, -1),\n",
       " (25872, -1),\n",
       " (28937, -1),\n",
       " (28190, 3080),\n",
       " (37072, -1),\n",
       " (38862, -1),\n",
       " (40012, -1)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_to_top_10_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "507612df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot how many of the good features were discarded\n",
    "# And separately plot the times to top 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "run_experiment(\n",
    "    cfg, task, task_iterator, model, criterion, optimizer,\n",
    "    repr_optimizer, distractor_tracker,\n",
    ")\n",
    "\n",
    "finish_experiment(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb99b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667dd436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
