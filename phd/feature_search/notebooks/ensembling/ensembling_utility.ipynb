{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f8d329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "import hydra\n",
    "\n",
    "from phd.feature_search.scripts.ensemble_feature_search import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2cda782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hydra.core.global_hydra.GlobalHydra().is_initialized():\n",
    "    hydra.initialize(config_path=\"../../conf\")\n",
    "\n",
    "# Load hydra config\n",
    "cfg = hydra.compose(\n",
    "    config_name = \"comet_sweeps/nonlinear_geoff_ablation_v5/base_config.yaml\",\n",
    "    overrides = [\n",
    "        \"task.n_features=30\",\n",
    "        \"task.n_real_features=30\",\n",
    "        \"task.noise_std=0.0\",\n",
    "        \"train.total_steps=2_000_000\",\n",
    "        \"seed=20250812\",\n",
    "        \"train.log_freq=500\",\n",
    "        \"comet_ml=false\",\n",
    "        \"wandb=false\",\n",
    "        \"model.hidden_dim=1280\", #1280\",\n",
    "        \"+model.ensemble_feature_selection_method=random\",\n",
    "        \"+model.feature_utility_mode=mean\",\n",
    "        \"+model.ensemble_utility_mode=objective_improvement\",\n",
    "        \"+model.prediction_mode=mean\",\n",
    "        \"+feature_recycling.ensemble_recycle_rate=0.0\",\n",
    "        \"+model.ensemble_dim=1280\",\n",
    "        \"+model.n_ensemble_members=1\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# yaml_cfg = omegaconf.OmegaConf.to_container(cfg, resolve=True)\n",
    "# print(yaml.dump(yaml_cfg, indent=2, width=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a074e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every time a new feature is introduced, check if it should be kept or not\n",
    "# If it should be kept, track how long for the feature to rise in utility to top 10%\n",
    "# But what is utility in an ensemble? I think for now I can just say it's the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "207cfb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|‚ñè         | 44500/2000000 [04:33<3:20:17, 162.72it/s, loss=0.443]\n"
     ]
    }
   ],
   "source": [
    "cfg = init_experiment(cfg.project, cfg)\n",
    "\n",
    "task, task_iterator, model, criterion, optimizer, repr_optimizer, recycler = \\\n",
    "    prepare_ltu_geoff_experiment(cfg)\n",
    "model.forward = model_distractor_forward_pass.__get__(model)\n",
    "\n",
    "distractor_tracker = DistractorTracker(\n",
    "    model,\n",
    "    cfg.task.distractor_chance,\n",
    "    tuple(cfg.task.distractor_mean_range),\n",
    "    tuple(cfg.task.distractor_std_range),\n",
    "    seed = seed_from_string(cfg.seed, 'distractor_tracker'),\n",
    ")\n",
    "\n",
    "# Gives a 1:1 hidden dim to ensemble input mapping\n",
    "model.ensemble_input_ids = torch.arange(\n",
    "        0, model.n_ensemble_members * model.ensemble_dim,\n",
    "        dtype = torch.long,\n",
    "        device = model.ensemble_input_ids.device,\n",
    "    ).reshape(model.n_ensemble_members, model.ensemble_dim)\n",
    "\n",
    "# Distractor setup\n",
    "n_hidden_units = model.input_layer.out_features\n",
    "distractor_tracker.process_new_features(torch.arange(n_hidden_units))\n",
    "\n",
    "# Training loop\n",
    "step = 0\n",
    "prev_pruned_idxs = set()\n",
    "prune_layer = model.activation\n",
    "pbar = tqdm(total=cfg.train.total_steps, desc='Training')\n",
    "\n",
    "# Flags\n",
    "log_utility_stats = cfg.train.get('log_utility_stats', False)\n",
    "log_pruning_stats = cfg.train.get('log_pruning_stats', False)\n",
    "log_model_stats = cfg.train.get('log_model_stats', False)\n",
    "\n",
    "# Initialize accumulators\n",
    "cumulant_stats = StandardizationStats(gamma=0.99)\n",
    "pruning_state = PruningState()\n",
    "cumulative_loss = np.float128(0.0)\n",
    "loss_accum = 0.0\n",
    "ensemble_loss_accum = 0.0\n",
    "mean_pred_loss_accum = 0.0\n",
    "pruned_accum = 0\n",
    "pruned_newest_feature_accum = 0\n",
    "n_steps_since_log = 0\n",
    "total_features_pruned = 0\n",
    "total_ensembles_pruned = 0\n",
    "prune_thresholds = []\n",
    "target_buffer = []\n",
    "\n",
    "times_to_top_10_percent = [] # Tuples of feature creation step and time to top 10%\n",
    "tracked_features = {} # Maps feature idx to the step it was introduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "33fa42cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature match counts: [24, 24, 25, 24, 24, 23, 24, 24, 25, 25, 23, 24, 24, 26, 24, 23, 23, 24, 26, 24]\n"
     ]
    }
   ],
   "source": [
    "# Get, for each target feature, how closely the closest learning network hidden unit matches it\n",
    "optimal_feature_weights = task.weights[0].T\n",
    "\n",
    "def compute_best_feature_match_counts(model, task):\n",
    "    optimal_feature_weights = task.weights[0].T\n",
    "    feature_matches = model.input_layer.weight.unsqueeze(dim=1) == optimal_feature_weights.unsqueeze(dim=0)\n",
    "    positive_feature_match_counts = feature_matches.sum(dim=2)\n",
    "    negative_feature_match_counts = (~feature_matches).sum(dim=2)\n",
    "    feature_match_counts = torch.maximum(positive_feature_match_counts, negative_feature_match_counts)\n",
    "    best_feature_match_counts = feature_match_counts.max(dim=0).values\n",
    "    return best_feature_match_counts\n",
    "\n",
    "best_feature_match_counts = compute_best_feature_match_counts(model, task)  \n",
    "\n",
    "print(f'Best feature match counts: {best_feature_match_counts.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5455902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 14500/2000000 [00:56<2:12:38, 249.47it/s, loss=0.448]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 92\u001b[0m\n\u001b[1;32m     87\u001b[0m         tracked_features\u001b[38;5;241m.\u001b[39mpop(feature_idx)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m### Forward Pass ###\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m outputs, param_inputs, aux \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistractor_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistractor_tracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m loss \u001b[38;5;241m=\u001b[39m aux[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     97\u001b[0m ensemble_loss_sum \u001b[38;5;241m=\u001b[39m aux[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble_losses\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/local_projects/phd_research/phd/feature_search/scripts/ensemble_feature_search.py:223\u001b[0m, in \u001b[0;36mmodel_distractor_forward_pass\u001b[0;34m(self, x, target, update_state, distractor_callback)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m distractor_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     hidden_features \u001b[38;5;241m=\u001b[39m distractor_callback(hidden_features)\n\u001b[0;32m--> 223\u001b[0m hidden_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Get the input features for each ensemble member\u001b[39;00m\n\u001b[1;32m    226\u001b[0m ensemble_input_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ensemble_input_features(hidden_features)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.10/site-packages/torch/nn/modules/module.py:1556\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1556\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tracing_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while step < cfg.train.total_steps:\n",
    "\n",
    "    ### Data Processing ###\n",
    "\n",
    "    # Generate batch of data\n",
    "    inputs, targets = next(task_iterator)\n",
    "\n",
    "    # Add noise to targets\n",
    "    if cfg.task.noise_std > 0:\n",
    "        targets += torch.randn_like(targets) * cfg.task.noise_std\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        standardized_targets, cumulant_stats = standardize_targets(targets, cumulant_stats)\n",
    "    \n",
    "    if cfg.train.standardize_cumulants:\n",
    "        targets = standardized_targets\n",
    "    target_buffer.extend(targets.view(-1).tolist())\n",
    "    \n",
    "    features, targets = inputs.to(cfg.device), targets.to(cfg.device)\n",
    "\n",
    "\n",
    "    ### Pruning ###\n",
    "\n",
    "    if log_pruning_stats:\n",
    "        pre_prune_feature_utilities = model.feature_utilities.ravel().cpu().clone().numpy()\n",
    "        pre_prune_ensemble_utilities = model.ensemble_utilities.cpu().clone().numpy()\n",
    "    \n",
    "    # Prune the model if necessary\n",
    "    prune_results = prune_model(\n",
    "        model, optimizer, distractor_tracker, pruning_state, cfg)\n",
    "    \n",
    "    # Update pruning metrics\n",
    "    total_features_pruned += prune_results['n_features_pruned']\n",
    "    total_ensembles_pruned += prune_results['n_ensembles_pruned']\n",
    "    \n",
    "    if prune_results['n_features_pruned'] > 0:\n",
    "        feature_idxs_pruned = prune_results['feature_idxs_pruned'].tolist()\n",
    "        \n",
    "        # Log pruning statistics\n",
    "        pruned_accum += len(feature_idxs_pruned)\n",
    "        n_new_pruned_features = len(set(feature_idxs_pruned).intersection(prev_pruned_idxs))\n",
    "        pruned_newest_feature_accum += n_new_pruned_features\n",
    "        prev_pruned_idxs = set(feature_idxs_pruned)\n",
    "        \n",
    "        if log_pruning_stats:\n",
    "            prune_thresholds.append(pre_prune_feature_utilities[feature_idxs_pruned].max())\n",
    "            \n",
    "        # Track new features\n",
    "        for feature_idx in feature_idxs_pruned:\n",
    "            # If the feature is pruned while still being tracked, then it never made it to top 10%\n",
    "            if feature_idx in tracked_features:\n",
    "                times_to_top_10_percent.append(\n",
    "                    (tracked_features[feature_idx], -1))\n",
    "                tracked_features.pop(feature_idx)\n",
    "            \n",
    "        new_feature_weights = model.input_layer.weight[feature_idxs_pruned]\n",
    "        feature_matches = new_feature_weights.unsqueeze(dim=1) == optimal_feature_weights.unsqueeze(dim=0)\n",
    "        positive_match_counts = feature_matches.sum(dim=2)\n",
    "        negative_match_counts = (~feature_matches).sum(dim=2)\n",
    "        match_counts = torch.maximum(positive_match_counts, negative_match_counts) # (n_features_pruned, n_target_features)\n",
    "        feature_improvement_matrix = match_counts > best_feature_match_counts.unsqueeze(dim=0)\n",
    "        \n",
    "        # Bool for each new feature that indicates if it is an overall improvement\n",
    "        new_best_feature = feature_improvement_matrix.any(dim=1) # (n_features_pruned,)\n",
    "        \n",
    "        # best_feature_match_counts = torch.maximum(\n",
    "        #     best_feature_match_counts,\n",
    "        #     match_counts.max(dim=0).values,\n",
    "        # )\n",
    "        \n",
    "        for i in range(len(feature_idxs_pruned)):\n",
    "            feature_idx = feature_idxs_pruned[i]\n",
    "            if new_best_feature[i]:\n",
    "                tracked_features[feature_idx] = step\n",
    "                \n",
    "        best_feature_match_counts = compute_best_feature_match_counts(model, task)\n",
    "    \n",
    "    \n",
    "    ### Track time to top 10% ###\n",
    "    \n",
    "    utility_treshold = torch.quantile(model.feature_utilities, 0.9)\n",
    "    feature_utilities = model.feature_utilities.cpu().clone().numpy()\n",
    "    for feature_idx in list(tracked_features.keys()):\n",
    "        if feature_utilities[feature_idx] > utility_treshold:\n",
    "            times_to_top_10_percent.append(\n",
    "                (tracked_features[feature_idx], step - tracked_features[feature_idx]))\n",
    "            tracked_features.pop(feature_idx)\n",
    "    \n",
    "    \n",
    "    ### Forward Pass ###\n",
    "    \n",
    "    outputs, param_inputs, aux = model(\n",
    "        features, targets, update_state=True,\n",
    "        distractor_callback=distractor_tracker.replace_features,\n",
    "    )\n",
    "    loss = aux['loss']\n",
    "    ensemble_loss_sum = aux['ensemble_losses'].sum()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if cfg.train.standardize_cumulants:\n",
    "            baseline_pred = torch.zeros_like(targets)\n",
    "        else:\n",
    "            baseline_pred = cumulant_stats.running_mean.cpu().view(1, 1)\n",
    "        mean_pred_loss = criterion(baseline_pred, targets)\n",
    "\n",
    "\n",
    "    ### Backward Pass ###\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    if repr_optimizer is not None:\n",
    "        repr_optimizer.zero_grad()\n",
    "    \n",
    "    if isinstance(optimizer, IDBD):\n",
    "        # Mean over batch dimension\n",
    "        param_inputs = {k: v.mean(dim=0) for k, v in param_inputs.items()}\n",
    "        retain_graph = optimizer.version == 'squared_grads'\n",
    "        ensemble_loss_sum.backward(retain_graph=retain_graph)\n",
    "        optimizer.step(aux['ensemble_predictions'], param_inputs)\n",
    "    else:\n",
    "        ensemble_loss_sum.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if repr_optimizer is not None:\n",
    "        repr_optimizer.step()\n",
    "        \n",
    "    \n",
    "    ### Metrics ###\n",
    "    \n",
    "    # Accumulate metrics\n",
    "    loss_accum += loss.item()\n",
    "    ensemble_loss_accum += ensemble_loss_sum.item()\n",
    "    cumulative_loss += loss.item()\n",
    "    mean_pred_loss_accum += mean_pred_loss.item()\n",
    "    n_steps_since_log += 1\n",
    "    \n",
    "    \n",
    "    ### Logging ###\n",
    "    \n",
    "    if step % cfg.train.log_freq == 0:\n",
    "        n_distractors = distractor_tracker.distractor_mask.sum().item()\n",
    "        n_real_features = distractor_tracker.distractor_mask.numel() - n_distractors\n",
    "        metrics = {\n",
    "            'step': step,\n",
    "            'samples': step * cfg.train.batch_size,\n",
    "            'loss': loss_accum / n_steps_since_log,\n",
    "            'avg_ensemble_loss': ensemble_loss_accum / model.n_ensemble_members / n_steps_since_log,\n",
    "            'cumulative_loss': float(cumulative_loss),\n",
    "            'mean_prediction_loss': mean_pred_loss_accum / n_steps_since_log,\n",
    "            'squared_targets': torch.tensor(target_buffer).square().mean().item(),\n",
    "            'n_distractors': n_distractors,\n",
    "            'n_real_features': n_real_features,\n",
    "        }\n",
    "\n",
    "        # Add model statistics separately for real and distractor features\n",
    "        if log_model_stats:\n",
    "            real_feature_masks = [\n",
    "                torch.ones(model.layers[0].weight.shape[1], dtype=torch.bool, device=model.layers[0].weight.device),\n",
    "                ~distractor_tracker.distractor_mask,\n",
    "            ]\n",
    "            metrics.update(get_model_statistics(\n",
    "                model, features, param_inputs, real_feature_masks, metric_prefix='real_'))\n",
    "            \n",
    "            distractor_feature_masks = [\n",
    "                real_feature_masks[0],\n",
    "                distractor_tracker.distractor_mask,\n",
    "            ]\n",
    "            metrics.update(get_model_statistics(\n",
    "                model, features, param_inputs, distractor_feature_masks, metric_prefix='distractor_'))\n",
    "\n",
    "        log_metrics(metrics, cfg, step=step)\n",
    "        \n",
    "        pbar.set_postfix(loss=metrics['loss'])\n",
    "        pbar.update(cfg.train.log_freq)\n",
    "        \n",
    "        # Reset accumulators\n",
    "        loss_accum = 0.0\n",
    "        mean_pred_loss_accum = 0.0\n",
    "        ensemble_loss_accum = 0.0\n",
    "        n_steps_since_log = 0\n",
    "        target_buffer = []\n",
    "\n",
    "    step += 1\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a21a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(40, -1),\n",
       " (40, -1),\n",
       " (57, -1),\n",
       " (65, -1),\n",
       " (145, -1),\n",
       " (208, -1),\n",
       " (230, -1),\n",
       " (249, -1),\n",
       " (274, -1),\n",
       " (310, -1),\n",
       " (307, -1),\n",
       " (333, -1),\n",
       " (357, -1),\n",
       " (331, -1),\n",
       " (12, -1),\n",
       " (411, -1),\n",
       " (421, -1),\n",
       " (306, -1),\n",
       " (455, -1),\n",
       " (503, -1),\n",
       " (550, -1),\n",
       " (542, -1),\n",
       " (604, -1),\n",
       " (587, -1),\n",
       " (649, -1),\n",
       " (694, -1),\n",
       " (695, -1),\n",
       " (753, -1),\n",
       " (754, -1),\n",
       " (776, -1),\n",
       " (797, -1),\n",
       " (843, -1),\n",
       " (855, -1),\n",
       " (861, -1),\n",
       " (905, -1),\n",
       " (137, -1),\n",
       " (917, -1),\n",
       " (913, -1),\n",
       " (977, -1),\n",
       " (978, -1),\n",
       " (992, -1),\n",
       " (1011, -1),\n",
       " (1086, -1),\n",
       " (1106, -1),\n",
       " (1117, -1),\n",
       " (1150, -1),\n",
       " (1177, -1),\n",
       " (1210, -1),\n",
       " (1296, -1),\n",
       " (1303, -1),\n",
       " (1317, -1),\n",
       " (1406, -1),\n",
       " (1425, -1),\n",
       " (1424, -1),\n",
       " (1470, -1),\n",
       " (1487, -1),\n",
       " (1542, -1),\n",
       " (1574, -1),\n",
       " (1581, -1),\n",
       " (1597, -1),\n",
       " (1614, -1),\n",
       " (1602, -1),\n",
       " (1579, -1),\n",
       " (1614, -1),\n",
       " (1646, -1),\n",
       " (1721, -1),\n",
       " (1739, -1),\n",
       " (1745, -1),\n",
       " (1764, -1),\n",
       " (1781, -1),\n",
       " (180, -1),\n",
       " (1796, -1),\n",
       " (1821, -1),\n",
       " (1831, -1),\n",
       " (1833, -1),\n",
       " (1847, -1),\n",
       " (1877, -1),\n",
       " (1968, -1),\n",
       " (1982, -1),\n",
       " (97, 1972),\n",
       " (1984, -1),\n",
       " (1917, -1),\n",
       " (1994, -1),\n",
       " (2035, -1),\n",
       " (2079, -1),\n",
       " (1997, -1),\n",
       " (2051, -1),\n",
       " (2133, -1),\n",
       " (2118, -1),\n",
       " (2196, -1),\n",
       " (2211, -1),\n",
       " (2166, -1),\n",
       " (2215, -1),\n",
       " (37, -1),\n",
       " (2243, -1),\n",
       " (2339, -1),\n",
       " (2364, -1),\n",
       " (2432, -1),\n",
       " (2430, -1),\n",
       " (2459, -1),\n",
       " (2494, -1),\n",
       " (2481, -1),\n",
       " (2584, -1),\n",
       " (2593, -1),\n",
       " (2584, -1),\n",
       " (2365, -1),\n",
       " (2673, -1),\n",
       " (2700, -1),\n",
       " (2724, -1),\n",
       " (2720, -1),\n",
       " (2749, -1),\n",
       " (2759, -1),\n",
       " (2674, -1),\n",
       " (2835, -1),\n",
       " (2836, -1),\n",
       " (2840, -1),\n",
       " (2859, -1),\n",
       " (2861, -1),\n",
       " (2874, -1),\n",
       " (2929, -1),\n",
       " (2969, -1),\n",
       " (3011, -1),\n",
       " (3004, -1),\n",
       " (3016, -1),\n",
       " (3006, -1),\n",
       " (3075, -1),\n",
       " (3080, -1),\n",
       " (3070, -1),\n",
       " (3114, -1),\n",
       " (3114, -1),\n",
       " (3133, -1),\n",
       " (3145, -1),\n",
       " (3142, -1),\n",
       " (3170, -1),\n",
       " (3229, -1),\n",
       " (3234, -1),\n",
       " (3257, -1),\n",
       " (3271, -1),\n",
       " (3316, -1),\n",
       " (3311, -1),\n",
       " (3347, -1),\n",
       " (3352, -1),\n",
       " (3367, -1),\n",
       " (3408, -1),\n",
       " (3423, -1),\n",
       " (3445, -1),\n",
       " (3462, -1),\n",
       " (3452, -1),\n",
       " (3480, -1),\n",
       " (3502, -1),\n",
       " (3540, -1),\n",
       " (3528, -1),\n",
       " (3562, -1),\n",
       " (3577, -1),\n",
       " (3605, -1),\n",
       " (3612, -1),\n",
       " (3637, -1),\n",
       " (3672, -1),\n",
       " (3707, -1),\n",
       " (3677, -1),\n",
       " (3707, -1),\n",
       " (3733, -1),\n",
       " (3827, -1),\n",
       " (3876, -1),\n",
       " (3925, -1),\n",
       " (3931, -1),\n",
       " (3988, -1),\n",
       " (3987, -1),\n",
       " (4028, -1),\n",
       " (3969, -1),\n",
       " (4056, -1),\n",
       " (3861, -1),\n",
       " (4045, -1),\n",
       " (4069, -1),\n",
       " (4092, -1),\n",
       " (4103, -1),\n",
       " (4118, -1),\n",
       " (4105, -1),\n",
       " (4153, -1),\n",
       " (4157, -1),\n",
       " (4153, -1),\n",
       " (4160, -1),\n",
       " (4171, -1),\n",
       " (4252, -1),\n",
       " (3947, -1),\n",
       " (4323, -1),\n",
       " (4403, -1),\n",
       " (4428, -1),\n",
       " (4404, -1),\n",
       " (4453, -1),\n",
       " (4437, -1),\n",
       " (4519, -1),\n",
       " (4509, -1),\n",
       " (4533, -1),\n",
       " (4538, -1),\n",
       " (4542, -1),\n",
       " (4534, -1),\n",
       " (4581, -1),\n",
       " (4141, -1),\n",
       " (4599, -1),\n",
       " (4591, -1),\n",
       " (4687, -1),\n",
       " (4689, -1),\n",
       " (4708, -1),\n",
       " (4689, -1),\n",
       " (4770, -1),\n",
       " (4768, -1),\n",
       " (4792, -1),\n",
       " (4808, -1),\n",
       " (4752, -1),\n",
       " (4834, -1),\n",
       " (4867, -1),\n",
       " (4894, -1),\n",
       " (4899, -1),\n",
       " (4906, -1),\n",
       " (4968, -1),\n",
       " (4983, -1),\n",
       " (4974, -1),\n",
       " (5017, -1),\n",
       " (5011, -1),\n",
       " (5064, -1),\n",
       " (5089, -1),\n",
       " (5065, -1),\n",
       " (5115, -1),\n",
       " (5149, -1),\n",
       " (5170, -1),\n",
       " (5201, -1),\n",
       " (5223, -1),\n",
       " (5232, -1),\n",
       " (5303, -1),\n",
       " (5339, -1),\n",
       " (5349, -1),\n",
       " (5402, -1),\n",
       " (5428, -1),\n",
       " (5483, -1),\n",
       " (5509, -1),\n",
       " (5498, -1),\n",
       " (5510, -1),\n",
       " (5549, -1),\n",
       " (5570, -1),\n",
       " (5614, -1),\n",
       " (5702, -1),\n",
       " (5689, -1),\n",
       " (5751, -1),\n",
       " (5776, -1),\n",
       " (5786, -1),\n",
       " (5811, -1),\n",
       " (5878, -1),\n",
       " (5885, -1),\n",
       " (5950, -1),\n",
       " (5961, -1),\n",
       " (6003, -1),\n",
       " (5996, -1),\n",
       " (6047, -1),\n",
       " (6072, -1),\n",
       " (6103, -1),\n",
       " (6099, -1),\n",
       " (6098, -1),\n",
       " (6135, -1),\n",
       " (6193, -1),\n",
       " (6223, -1),\n",
       " (6212, -1),\n",
       " (6246, -1),\n",
       " (6258, -1),\n",
       " (6284, -1),\n",
       " (6282, -1),\n",
       " (3640, 2749),\n",
       " (6326, -1),\n",
       " (6307, -1),\n",
       " (6335, -1),\n",
       " (6399, -1),\n",
       " (6400, -1),\n",
       " (6522, -1),\n",
       " (6517, -1),\n",
       " (6552, -1),\n",
       " (6609, -1),\n",
       " (6656, -1),\n",
       " (6627, -1),\n",
       " (6634, -1),\n",
       " (6683, -1),\n",
       " (6703, -1),\n",
       " (6716, -1),\n",
       " (6706, -1),\n",
       " (6724, -1),\n",
       " (6725, -1),\n",
       " (6777, -1),\n",
       " (6765, -1),\n",
       " (6803, -1),\n",
       " (6870, -1),\n",
       " (6885, -1),\n",
       " (6902, -1),\n",
       " (6923, -1),\n",
       " (6923, -1),\n",
       " (6935, -1),\n",
       " (5110, -1),\n",
       " (6967, -1),\n",
       " (6984, -1),\n",
       " (6990, -1),\n",
       " (6998, -1),\n",
       " (7021, -1),\n",
       " (7085, -1),\n",
       " (7116, -1),\n",
       " (7127, -1),\n",
       " (7175, -1),\n",
       " (7201, -1),\n",
       " (7223, -1),\n",
       " (7226, -1),\n",
       " (7249, -1),\n",
       " (7249, -1),\n",
       " (7262, -1),\n",
       " (7261, -1),\n",
       " (7302, -1),\n",
       " (7333, -1),\n",
       " (7346, -1),\n",
       " (7421, -1),\n",
       " (7429, -1),\n",
       " (7437, -1),\n",
       " (7462, -1),\n",
       " (7486, -1),\n",
       " (7498, -1),\n",
       " (7415, -1),\n",
       " (7514, -1),\n",
       " (7523, -1),\n",
       " (7525, -1),\n",
       " (7547, -1),\n",
       " (7565, -1),\n",
       " (7560, -1),\n",
       " (7653, -1),\n",
       " (7668, -1),\n",
       " (7676, -1),\n",
       " (7685, -1),\n",
       " (7692, -1),\n",
       " (7802, -1),\n",
       " (7803, -1),\n",
       " (7824, -1),\n",
       " (7888, -1),\n",
       " (7896, -1),\n",
       " (7929, -1),\n",
       " (7930, -1),\n",
       " (7922, -1),\n",
       " (7971, -1),\n",
       " (7990, -1),\n",
       " (8014, -1),\n",
       " (8055, -1),\n",
       " (8055, -1),\n",
       " (8059, -1),\n",
       " (8017, -1),\n",
       " (8095, -1),\n",
       " (8101, -1),\n",
       " (8150, -1),\n",
       " (8161, -1),\n",
       " (8200, -1),\n",
       " (8216, -1),\n",
       " (8235, -1),\n",
       " (8246, -1),\n",
       " (8245, -1),\n",
       " (8306, -1),\n",
       " (8332, -1),\n",
       " (8341, -1),\n",
       " (8339, -1),\n",
       " (8425, -1),\n",
       " (8389, -1),\n",
       " (8461, -1),\n",
       " (8445, -1),\n",
       " (8533, -1),\n",
       " (8604, -1),\n",
       " (8393, -1),\n",
       " (8649, -1),\n",
       " (8670, -1),\n",
       " (8662, -1),\n",
       " (8683, -1),\n",
       " (8681, -1),\n",
       " (8685, -1),\n",
       " (8717, -1),\n",
       " (8718, -1),\n",
       " (8735, -1),\n",
       " (8745, -1),\n",
       " (8757, -1),\n",
       " (8773, -1),\n",
       " (8818, -1),\n",
       " (8957, -1),\n",
       " (8986, -1),\n",
       " (9082, -1),\n",
       " (9075, -1),\n",
       " (9096, -1),\n",
       " (9149, -1),\n",
       " (9158, -1),\n",
       " (9175, -1),\n",
       " (9204, -1),\n",
       " (9190, -1),\n",
       " (9204, -1),\n",
       " (9246, -1),\n",
       " (9289, -1),\n",
       " (9283, -1),\n",
       " (9321, -1),\n",
       " (9319, -1),\n",
       " (9331, -1),\n",
       " (9349, -1),\n",
       " (9368, -1),\n",
       " (9411, -1),\n",
       " (9424, -1),\n",
       " (9443, -1),\n",
       " (9488, -1),\n",
       " (9519, -1),\n",
       " (9528, -1),\n",
       " (9536, -1),\n",
       " (9627, -1),\n",
       " (9487, -1),\n",
       " (9650, -1),\n",
       " (9594, -1),\n",
       " (9702, -1),\n",
       " (9699, -1),\n",
       " (9726, -1),\n",
       " (9801, -1),\n",
       " (9801, -1),\n",
       " (9816, -1),\n",
       " (9823, -1),\n",
       " (9860, -1),\n",
       " (9958, -1),\n",
       " (9986, -1),\n",
       " (10068, -1),\n",
       " (10106, -1),\n",
       " (10107, -1),\n",
       " (192, 9995),\n",
       " (10131, -1),\n",
       " (10189, -1),\n",
       " (10234, -1),\n",
       " (10288, -1),\n",
       " (10292, -1),\n",
       " (10343, -1),\n",
       " (10403, -1),\n",
       " (10399, -1),\n",
       " (10468, -1),\n",
       " (10373, -1),\n",
       " (10439, -1),\n",
       " (10542, -1),\n",
       " (10569, -1),\n",
       " (10576, -1),\n",
       " (10613, -1),\n",
       " (10638, -1),\n",
       " (10670, -1),\n",
       " (10728, -1),\n",
       " (10723, -1),\n",
       " (10761, -1),\n",
       " (10787, -1),\n",
       " (10870, -1),\n",
       " (10893, -1),\n",
       " (10890, -1),\n",
       " (10884, -1),\n",
       " (10918, -1),\n",
       " (10921, -1),\n",
       " (8412, -1),\n",
       " (10978, -1),\n",
       " (9286, -1),\n",
       " (11015, -1),\n",
       " (11019, -1),\n",
       " (11029, -1),\n",
       " (11045, -1),\n",
       " (11053, -1),\n",
       " (11062, -1),\n",
       " (11120, -1),\n",
       " (11125, -1),\n",
       " (11137, -1),\n",
       " (11135, -1),\n",
       " (11156, -1),\n",
       " (11166, -1),\n",
       " (11216, -1),\n",
       " (11248, -1),\n",
       " (11258, -1),\n",
       " (11264, -1),\n",
       " (11270, -1),\n",
       " (11282, -1),\n",
       " (11341, -1),\n",
       " (11397, -1),\n",
       " (11431, -1),\n",
       " (11444, -1),\n",
       " (11451, -1),\n",
       " (11456, -1),\n",
       " (11471, -1),\n",
       " (11484, -1),\n",
       " (11494, -1),\n",
       " (11526, -1),\n",
       " (11531, -1),\n",
       " (11543, -1),\n",
       " (11588, -1),\n",
       " (11622, -1),\n",
       " (11660, -1),\n",
       " (11665, -1),\n",
       " (11689, -1),\n",
       " (11732, -1),\n",
       " (11830, -1),\n",
       " (11864, -1),\n",
       " (11876, -1),\n",
       " (11888, -1),\n",
       " (11919, -1),\n",
       " (11901, -1),\n",
       " (11998, -1),\n",
       " (12024, -1),\n",
       " (12050, -1),\n",
       " (12086, -1),\n",
       " (12054, -1),\n",
       " (12103, -1),\n",
       " (12102, -1),\n",
       " (12207, -1),\n",
       " (12217, -1),\n",
       " (12218, -1),\n",
       " (12247, -1),\n",
       " (12429, -1),\n",
       " (12419, -1),\n",
       " (12452, -1),\n",
       " (12474, -1),\n",
       " (12358, -1),\n",
       " (12477, -1),\n",
       " (12594, -1),\n",
       " (12582, -1),\n",
       " (12656, -1),\n",
       " (12639, -1),\n",
       " (12677, -1),\n",
       " (12716, -1),\n",
       " (12756, -1),\n",
       " (12743, -1),\n",
       " (12812, -1),\n",
       " (12812, -1),\n",
       " (12826, -1),\n",
       " (12823, -1),\n",
       " (12838, -1),\n",
       " (12860, -1),\n",
       " (12854, -1),\n",
       " (12880, -1),\n",
       " (12898, -1),\n",
       " (12903, -1),\n",
       " (12938, -1),\n",
       " (12974, -1),\n",
       " (13031, -1),\n",
       " (13098, -1),\n",
       " (13097, -1),\n",
       " (12996, -1),\n",
       " (13119, -1),\n",
       " (13149, -1),\n",
       " (13163, -1),\n",
       " (13166, -1),\n",
       " (13189, -1),\n",
       " (13197, -1),\n",
       " (13253, -1),\n",
       " (13304, -1),\n",
       " (13354, -1),\n",
       " (13383, -1),\n",
       " (13432, -1),\n",
       " (13444, -1),\n",
       " (13445, -1),\n",
       " (13420, -1),\n",
       " (13481, -1),\n",
       " (13432, -1),\n",
       " (13551, -1),\n",
       " (13556, -1),\n",
       " (13540, -1),\n",
       " (13580, -1),\n",
       " (13631, -1),\n",
       " (13691, -1),\n",
       " (13778, -1),\n",
       " (13829, -1),\n",
       " (13808, -1),\n",
       " (13870, -1),\n",
       " (13880, -1),\n",
       " (13924, -1),\n",
       " (13921, -1),\n",
       " (13973, -1),\n",
       " (14006, -1),\n",
       " (14000, -1),\n",
       " (14007, -1),\n",
       " (14047, -1),\n",
       " (14061, -1),\n",
       " (14089, -1),\n",
       " (14114, -1)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 14500/2000000 [01:07<2:12:38, 249.47it/s, loss=0.448]"
     ]
    }
   ],
   "source": [
    "times_to_top_10_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "507612df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot how many of the good features were discarded\n",
    "# And separately plot the times to top 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "run_experiment(\n",
    "    cfg, task, task_iterator, model, criterion, optimizer,\n",
    "    repr_optimizer, distractor_tracker,\n",
    ")\n",
    "\n",
    "finish_experiment(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb99b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667dd436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
